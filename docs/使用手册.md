# 剧本杀知识库系统 — 使用手册

## 1. 系统简介

剧本杀知识库系统是一个 AI 驱动的文档处理与知识管理平台，核心目标是为 AI 生成剧本杀提供全面的知识基础。系统能够：

- 读取剧本杀 PDF 文档，自动提取文本并向量化存储
- 利用 LLM 自动提取 13 种结构化信息（剧本元数据、诡计、角色、剧本结构、故事背景、剧本格式、玩家剧本、线索、推理链、误导手段、游戏机制、叙事技法、情感设计）
- 支持多维度结构化查询与语义搜索的混合检索
- 提供基于知识库的智能问答（支持多轮对话和流式输出）

技术栈：Next.js (App Router) + LangGraph + Supabase (PostgreSQL + pgvector) + OpenAI

## 2. 环境准备

### 2.1 前置依赖

| 依赖 | 版本要求 | 说明 |
|------|----------|------|
| Node.js | ≥ 18 | JavaScript 运行时 |
| npm | ≥ 9 | 包管理器 |
| Supabase 项目 | — | 提供 PostgreSQL + pgvector + Storage |
| OpenAI API Key | — | 用于 Embedding 和 LLM 调用 |
| LangSmith API Key | 可选 | 用于工作流追踪和调试 |

### 2.2 获取代码

```bash
git clone <repository-url>
cd murder-mystery-knowledge-base
npm install
```

### 2.3 配置环境变量

复制示例文件并填入实际值：

```bash
cp .env.local.example .env.local
```

编辑 `.env.local`：

```env
# Supabase
NEXT_PUBLIC_SUPABASE_URL=your-supabase-project-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key

# OpenAI
OPENAI_API_KEY=your-openai-api-key

# LangSmith（可选，用于工作流追踪）
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_PROJECT=murder-mystery-knowledge-base
```

### 2.4 初始化数据库

在 Supabase 项目中执行数据库迁移脚本，创建所有表和索引：

1. 打开 Supabase Dashboard → SQL Editor
2. 将 `supabase/migrations/00001_initial_schema.sql` 的内容粘贴并执行
3. 确认所有表创建成功（共 30+ 张表）

此外，需要创建向量搜索的 RPC 函数：

```sql
CREATE OR REPLACE FUNCTION match_documents(
  query_embedding vector(1536),
  match_count int DEFAULT 10,
  match_threshold float DEFAULT 0.5
) RETURNS TABLE (
  id uuid,
  document_id uuid,
  content text,
  page_start int,
  page_end int,
  chunk_index int,
  similarity float
) LANGUAGE plpgsql AS $$
BEGIN
  RETURN QUERY
  SELECT
    dc.id,
    dc.document_id,
    dc.content,
    dc.page_start,
    dc.page_end,
    dc.chunk_index,
    1 - (dc.embedding <=> query_embedding) AS similarity
  FROM document_chunks dc
  WHERE dc.embedding IS NOT NULL
    AND 1 - (dc.embedding <=> query_embedding) > match_threshold
  ORDER BY dc.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

还需要在 Supabase Storage 中创建一个名为 `documents` 的存储桶（Bucket），用于存放上传的 PDF 文件。

### 2.5 启动开发服务器

```bash
npm run dev
```

浏览器访问 [http://localhost:3000](http://localhost:3000) 即可看到系统首页。

## 3. 功能使用指南

系统首页提供三个核心入口：文档上传、智能问答、结构化检索。

### 3.1 文档上传

访问路径：`/upload`

#### 操作步骤

1. 进入文档上传页面
2. 通过以下方式上传 PDF 文件：
   - 将 PDF 文件拖拽到上传区域
   - 点击上传区域选择文件
3. 系统自动执行以下处理流程：
   - 文件上传至 Supabase Storage
   - PDF 文本提取
   - 语义分块（chunk_size=1000, overlap=200）
   - 向量化（OpenAI text-embedding-3-small）
   - 结构化信息提取（13 种实体类型）
4. 页面实时显示处理状态

#### 文档处理状态

| 状态 | 说明 |
|------|------|
| 上传中 | 文件正在上传至存储服务 |
| 解析中 | 正在提取 PDF 文本内容 |
| 分块中 | 正在将文本按语义边界分割 |
| 向量化中 | 正在生成文本向量 |
| 提取中 | 正在使用 LLM 提取结构化信息 |
| 已完成 | 所有处理步骤完成 |
| 失败 | 处理过程中出现错误 |

#### 限制与注意事项

- 仅支持 PDF 格式，最大 50MB
- 非 PDF 文件或空 PDF 会返回明确的错误提示
- 提取失败不影响文档的语义搜索功能（文档已完成向量化）

#### 已上传文档列表

页面下方展示所有已上传文档，包含文件名、页数、分块数、上传日期和处理状态。

### 3.2 智能问答

访问路径：`/chat`

#### 操作步骤

1. 进入聊天问答页面
2. 在底部输入框输入自然语言问题
3. 按 Enter 或点击发送按钮
4. 系统以流式方式实时返回回答

#### 功能特性

- 流式输出：回答内容逐字显示，减少等待感
- 引用来源：回答中标注引用的剧本名称和页码
- 多轮对话：同一会话中支持追问和上下文关联
- 智能路由：系统自动判断查询意图，选择最优检索策略

#### 问答示例

```
用户：有哪些密室类型的诡计？
助手：根据知识库中的记录，密室类型的诡计包括...
      [引用来源: 《XX剧本》第12页]

用户：这些诡计中哪个最难破解？
助手：在上述密室诡计中，...（基于上下文继续回答）
```

#### 注意事项

- 如果问题超出知识库范围，系统会明确告知
- 新开页面会创建新的会话，历史对话不会跨会话保留

### 3.3 结构化检索

访问路径：`/search`

#### 操作步骤

1. 进入结构化检索页面
2. 填写筛选条件（至少填写一项）
3. 点击"搜索"按钮
4. 查看结果卡片

#### 支持的筛选维度

| 筛选项 | 类型 | 说明 |
|--------|------|------|
| 自然语言查询 | 文本输入 | 语义搜索，可与结构化条件混合使用 |
| 诡计类型 | 下拉选择 | 密室、不在场证明、凶器隐藏、毒杀、伪装、其他 |
| 角色身份 | 下拉选择 | 凶手、侦探、嫌疑人、受害者、NPC |
| 时代设定 | 文本输入 | 如：民国、现代、古代 |
| 幕数 | 数字输入 | 剧本的分幕数量 |
| 字数范围 | 数字输入 | 玩家剧本的最小/最大字数 |
| 线索类型 | 下拉选择 | 物证、证言、文件、环境线索 |
| 误导类型 | 下拉选择 | 虚假线索、时间误导、身份伪装、动机误导 |
| 剧本类型标签 | 文本输入 | 逗号分隔，如：硬核推理,情感沉浸 |
| 适合人数 | 数字输入 | 适合的玩家人数 |
| 玩法类型 | 文本输入 | 如：推理投凶、阵营对抗 |
| 叙事结构 | 下拉选择 | 线性、非线性、多线交织、倒叙 |

#### 检索策略

系统根据输入自动选择检索策略：

- 仅填写结构化条件 → 精确匹配查询
- 仅输入自然语言 → 语义相似度搜索
- 同时填写两者 → 混合检索（RRF 算法合并排序）

#### 结果展示

每个结果卡片包含：
- 实体类型标签（如"诡计"、"角色"、"线索"等）
- 摘要信息
- 来源文档名称和页码
- 相关度评分（百分比）

## 4. API 接口参考

### 4.1 文档上传

```
POST /api/upload
Content-Type: multipart/form-data
```

请求参数：
- `file`：PDF 文件（必填）

响应示例：
```json
{
  "documentId": "uuid",
  "status": "completed",
  "filename": "script.pdf",
  "pageCount": 42,
  "chunkCount": 85
}
```

错误码：
| HTTP 状态码 | code | 说明 |
|-------------|------|------|
| 400 | MISSING_FILE | 未提供文件 |
| 400 | INVALID_FILE_TYPE | 非 PDF 文件 |
| 413 | FILE_TOO_LARGE | 文件超过 50MB |
| 422 | EMPTY_CONTENT | PDF 内容为空或无法解析 |
| 503 | STORAGE_ERROR | 存储服务不可用 |

### 4.2 智能问答

```
POST /api/chat
Content-Type: application/json
```

请求体：
```json
{
  "message": "有哪些密室诡计？",
  "session_id": "可选，已有会话ID"
}
```

响应格式：Server-Sent Events (SSE)

```
data: {"type":"session_id","session_id":"uuid"}

data: {"type":"chunk","content":"根据"}

data: {"type":"chunk","content":"知识库..."}

data: {"type":"sources","sources":[{"title":"XX剧本","page":12,"score":0.85}]}

data: [DONE]
```

### 4.3 结构化检索

```
POST /api/search
Content-Type: application/json
```

请求体：
```json
{
  "query": "自然语言查询（可选）",
  "filters": {
    "trick_type": "locked_room",
    "character_identity": "murderer",
    "era": "民国",
    "act_count": 3,
    "clue_type": "physical_evidence",
    "misdirection_type": "false_clue",
    "script_type_tags": ["硬核推理"],
    "player_count": 6,
    "play_type": "推理投凶",
    "narrative_structure_type": "nonlinear",
    "word_count_range": { "min": 3000, "max": 8000 }
  }
}
```

响应示例：
```json
{
  "items": [
    {
      "type": "trick",
      "data": { "name": "密室机关", "mechanism": "..." },
      "source": { "document_name": "XX剧本.pdf", "page": 15 },
      "score": 0.92
    }
  ],
  "total": 1
}
```

### 4.4 文档列表

```
GET /api/documents
```

响应示例：
```json
{
  "items": [
    {
      "id": "uuid",
      "filename": "script.pdf",
      "status": "completed",
      "upload_date": "2026-02-19T10:00:00Z",
      "page_count": 42,
      "chunk_count": 85
    }
  ],
  "total": 1
}
```

## 5. 系统架构概览

### 5.1 三条核心工作流

系统由三条 LangGraph 工作流驱动：

```
┌─────────────────────────────────────────────────────┐
│  Ingestion Pipeline（摄入管线）                       │
│  PDF 上传 → 文本提取 → 语义分块 → 向量化存储           │
│       ↓ 完成后自动触发                                │
│  Extraction Pipeline（提取管线）                      │
│  加载文档块 → 并行提取13种实体 → 置信度评估 → 存储      │
└─────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────┐
│  Retrieval Pipeline（检索管线）                       │
│  用户查询 → 意图分析 → 路由搜索 → 结果合并 → 生成回答  │
└─────────────────────────────────────────────────────┘
```

### 5.2 提取的 13 种实体类型

| 实体类型 | 说明 |
|----------|------|
| script_metadata | 剧本元数据（名称、作者、人数、时长、难度等） |
| trick | 诡计（密室、不在场证明、凶器隐藏等） |
| character | 角色（姓名、身份、动机、性格、关系） |
| script_structure | 剧本结构（时间线、场景、幕） |
| story_background | 故事背景（时代、地点、世界观） |
| script_format | 剧本格式（分幕结构、排版风格） |
| player_script | 玩家剧本（角色剧本内容和字数） |
| clue | 线索（物证、证言、文件、环境线索） |
| reasoning_chain | 推理链（从线索到结论的推导路径） |
| misdirection | 误导手段（虚假线索、时间误导等） |
| game_mechanics | 游戏机制（玩法类型、特殊环节、胜利条件） |
| narrative_technique | 叙事技法（叙事视角、结构、悬念、伏笔） |
| emotional_design | 情感设计（目标情感、高潮点、情感弧线） |

### 5.3 置信度与审核机制

LLM 在提取每个字段时会输出置信度分数（0-1）。当任一字段的置信度低于 0.7 时，该记录被标记为"待审核"（pending_review）；所有字段置信度均 ≥ 0.7 时标记为"已通过"（approved）。

## 6. 项目结构

```
├── app/                          # Next.js App Router 页面和 API
│   ├── page.tsx                  # 首页（导航入口）
│   ├── upload/page.tsx           # 文档上传页面
│   ├── chat/page.tsx             # 智能问答页面
│   ├── search/page.tsx           # 结构化检索页面
│   └── api/
│       ├── upload/route.ts       # 文档上传 API
│       ├── chat/route.ts         # 聊天 API（SSE 流式）
│       ├── search/route.ts       # 结构化检索 API
│       └── documents/route.ts    # 文档列表 API
├── components/                   # React 组件
│   ├── ChatMessage.tsx           # 聊天消息组件
│   ├── SearchFilters.tsx         # 检索筛选面板
│   └── ResultCard.tsx            # 结果卡片组件
├── lib/
│   ├── supabase.ts               # Supabase 客户端
│   ├── schemas/index.ts          # Zod Schema 定义（13 种实体）
│   ├── services/                 # 数据库服务层
│   │   ├── document.ts           # 文档 CRUD
│   │   ├── extraction.ts         # 结构化数据 CRUD
│   │   ├── vector.ts             # 向量存储与搜索
│   │   ├── search.ts             # 混合检索
│   │   ├── chat.ts               # 聊天会话管理
│   │   └── utils.ts              # 工具函数（RRF 算法等）
│   ├── utils/
│   │   └── parse-sse.ts          # SSE 事件解析器
│   └── workflows/                # LangGraph 工作流
│       ├── ingestion/            # 摄入管线
│       ├── extraction/           # 提取管线
│       └── retrieval/            # 检索管线
├── supabase/migrations/          # 数据库迁移脚本
├── __tests__/                    # 测试文件
├── .env.local.example            # 环境变量示例
├── package.json
├── vitest.config.ts              # 测试配置
└── tsconfig.json
```

## 7. 开发与测试

### 7.1 常用命令

```bash
# 启动开发服务器
npm run dev

# 构建生产版本
npm run build

# 启动生产服务器
npm start

# 运行代码检查
npm run lint

# 运行测试（单次执行）
npm test

# 运行测试（监听模式）
npm run test:watch
```

### 7.2 测试框架

- 单元测试：Vitest
- 属性测试：fast-check
- 测试超时：30 秒（属性测试可能需要更长时间）

## 8. 常见问题

### Q: 上传 PDF 后一直显示"处理中"？

检查以下几点：
1. OpenAI API Key 是否正确配置
2. Supabase 连接是否正常
3. 查看终端日志是否有错误输出

### Q: 聊天回答质量不高？

- 确保已上传足够多的剧本杀文档
- 尝试更具体的问题描述
- 检查文档是否已完成提取（状态为"已完成"）

### Q: 结构化检索没有结果？

- 确认已有文档完成了结构化信息提取
- 尝试放宽筛选条件
- 使用自然语言查询作为补充

### Q: 如何查看工作流执行详情？

配置 LangSmith 环境变量后，所有工作流的执行记录会自动上报至 LangSmith 平台，可在其 Dashboard 中查看每个节点的输入输出和执行耗时。
